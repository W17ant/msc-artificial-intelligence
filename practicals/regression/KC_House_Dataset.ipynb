{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "37e9551c-d169-438d-9684-1956c8a110ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fc0f5d1d-9331-4752-82f6-55b284dd8ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"kc_house_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dd93ec49-f0cc-4e2c-81a0-1f09eea425cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 2 rows with missing values\n",
    "dataset = dataset.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a622dd73-2bce-4411-b409-240bdc9a88a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[ : ,3: ]\n",
    "Y = dataset.iloc[ : ,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0c887d08-0b4a-4150-b1e8-300d1f889bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Scale X\n",
    "mmScaler_X = MinMaxScaler()\n",
    "X = mmScaler_X.fit_transform(X.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "26468508-b36b-4bb7-a990-461fbb024501",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, Y, test_size = 0.2, random_state=0)#20% OF DATA 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4bf1ec33-e8a7-4386-a20d-0034dfea9ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries and functions for NN\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.optimizers import Adam #GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7d6a88fa-86cb-49f3-8c88-ea99153f814c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build the network\n",
    "model = Sequential()\n",
    "#input layer is automatically identified during the fit function\n",
    "model.add(Dense(30, activation=\"relu\"))\n",
    "model.add(Dense(30, activation=\"relu\"))\n",
    "model.add(Dense(40, activation=\"relu\"))\n",
    "model.add(Dense(40, activation=\"relu\"))\n",
    "model.add(Dense(40, activation=\"relu\"))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "91822360-e37b-4681-8dd8-4b6e484aaabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"Adam\", loss=\"mae\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ccc58176-1b48-4e5c-8874-7f86d0b899f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 937us/step - loss: 318102.5938 - val_loss: 180386.6406\n",
      "Epoch 2/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 792us/step - loss: 166720.2188 - val_loss: 156299.0938\n",
      "Epoch 3/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step - loss: 141013.4062 - val_loss: 130683.0547\n",
      "Epoch 4/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step - loss: 126123.3594 - val_loss: 125349.6016\n",
      "Epoch 5/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 776us/step - loss: 121562.5469 - val_loss: 121689.5859\n",
      "Epoch 6/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 799us/step - loss: 119394.7656 - val_loss: 119462.4844\n",
      "Epoch 7/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825us/step - loss: 117940.0156 - val_loss: 117795.1094\n",
      "Epoch 8/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - loss: 116491.2969 - val_loss: 116202.7422\n",
      "Epoch 9/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - loss: 115423.0625 - val_loss: 114994.7969\n",
      "Epoch 10/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779us/step - loss: 114318.6172 - val_loss: 113582.8281\n",
      "Epoch 11/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852us/step - loss: 113304.7969 - val_loss: 113026.3906\n",
      "Epoch 12/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step - loss: 112423.7031 - val_loss: 112351.0703\n",
      "Epoch 13/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step - loss: 111699.9297 - val_loss: 110295.9062\n",
      "Epoch 14/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 785us/step - loss: 110659.1797 - val_loss: 109513.8672\n",
      "Epoch 15/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833us/step - loss: 109974.3516 - val_loss: 108875.1797\n",
      "Epoch 16/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step - loss: 109272.9766 - val_loss: 107994.8594\n",
      "Epoch 17/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779us/step - loss: 108741.5938 - val_loss: 107121.2188\n",
      "Epoch 18/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 906us/step - loss: 108247.1797 - val_loss: 106527.8750\n",
      "Epoch 19/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 946us/step - loss: 107722.1016 - val_loss: 106677.7188\n",
      "Epoch 20/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step - loss: 107216.4062 - val_loss: 105600.8906\n",
      "Epoch 21/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - loss: 106677.0078 - val_loss: 105130.4219\n",
      "Epoch 22/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step - loss: 106329.4766 - val_loss: 104408.4219\n",
      "Epoch 23/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 105740.2578 - val_loss: 104035.5312\n",
      "Epoch 24/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step - loss: 105504.2734 - val_loss: 103647.9844\n",
      "Epoch 25/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step - loss: 105195.0781 - val_loss: 103126.4609\n",
      "Epoch 26/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - loss: 104836.2812 - val_loss: 103059.0000\n",
      "Epoch 27/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 792us/step - loss: 104423.0703 - val_loss: 102509.7969\n",
      "Epoch 28/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 790us/step - loss: 104203.2266 - val_loss: 102296.0312\n",
      "Epoch 29/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step - loss: 104089.6484 - val_loss: 102055.7969\n",
      "Epoch 30/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 864us/step - loss: 103734.7031 - val_loss: 101911.6875\n",
      "Epoch 31/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - loss: 103394.0156 - val_loss: 101519.1406\n",
      "Epoch 32/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step - loss: 103349.1172 - val_loss: 101796.1016\n",
      "Epoch 33/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 786us/step - loss: 102891.9297 - val_loss: 101311.7031\n",
      "Epoch 34/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 799us/step - loss: 102691.3750 - val_loss: 100903.7656\n",
      "Epoch 35/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 959us/step - loss: 102411.5156 - val_loss: 100492.5703\n",
      "Epoch 36/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step - loss: 102208.0391 - val_loss: 100834.5859\n",
      "Epoch 37/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step - loss: 102087.0625 - val_loss: 100195.5625\n",
      "Epoch 38/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step - loss: 101870.9844 - val_loss: 100565.4688\n",
      "Epoch 39/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - loss: 101556.5859 - val_loss: 99944.9375\n",
      "Epoch 40/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - loss: 101406.0781 - val_loss: 100080.5078\n",
      "Epoch 41/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 889us/step - loss: 101278.0859 - val_loss: 100260.6641\n",
      "Epoch 42/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828us/step - loss: 101032.1406 - val_loss: 99195.3125\n",
      "Epoch 43/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 791us/step - loss: 100736.9219 - val_loss: 99465.0859\n",
      "Epoch 44/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833us/step - loss: 100567.4375 - val_loss: 99044.6719\n",
      "Epoch 45/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step - loss: 100373.7031 - val_loss: 99405.6250\n",
      "Epoch 46/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step - loss: 99984.2578 - val_loss: 99716.0781\n",
      "Epoch 47/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 785us/step - loss: 99977.7812 - val_loss: 99266.3906\n",
      "Epoch 48/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829us/step - loss: 99603.5156 - val_loss: 99441.3047\n",
      "Epoch 49/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - loss: 99413.7734 - val_loss: 98283.2344\n",
      "Epoch 50/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step - loss: 99303.7422 - val_loss: 98105.0859\n",
      "Epoch 51/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 823us/step - loss: 99062.0391 - val_loss: 98429.0312\n",
      "Epoch 52/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 932us/step - loss: 98794.3438 - val_loss: 97958.9453\n",
      "Epoch 53/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - loss: 98816.6562 - val_loss: 99385.2812\n",
      "Epoch 54/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - loss: 98674.8906 - val_loss: 98427.7109\n",
      "Epoch 55/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step - loss: 98520.8750 - val_loss: 97755.1484\n",
      "Epoch 56/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 784us/step - loss: 98122.0391 - val_loss: 97502.3281\n",
      "Epoch 57/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step - loss: 98110.0938 - val_loss: 97528.6016\n",
      "Epoch 58/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - loss: 97956.3203 - val_loss: 97446.8281\n",
      "Epoch 59/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - loss: 97679.7188 - val_loss: 97280.9922\n",
      "Epoch 60/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - loss: 97513.2344 - val_loss: 97405.0078\n",
      "Epoch 61/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - loss: 97593.8203 - val_loss: 97494.3438\n",
      "Epoch 62/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step - loss: 97442.8281 - val_loss: 97187.0625\n",
      "Epoch 63/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - loss: 97248.5547 - val_loss: 97494.2500\n",
      "Epoch 64/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step - loss: 97093.1250 - val_loss: 96920.3359\n",
      "Epoch 65/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - loss: 96930.4766 - val_loss: 97665.1562\n",
      "Epoch 66/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step - loss: 96662.7266 - val_loss: 96820.6484\n",
      "Epoch 67/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step - loss: 96690.8281 - val_loss: 97367.4141\n",
      "Epoch 68/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868us/step - loss: 96725.0547 - val_loss: 96687.0391\n",
      "Epoch 69/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 771us/step - loss: 96525.2031 - val_loss: 97036.2344\n",
      "Epoch 70/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step - loss: 96401.8359 - val_loss: 98889.4297\n",
      "Epoch 71/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819us/step - loss: 96467.3516 - val_loss: 96793.2344\n",
      "Epoch 72/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833us/step - loss: 96083.4531 - val_loss: 96325.3281\n",
      "Epoch 73/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - loss: 96053.1484 - val_loss: 96791.9141\n",
      "Epoch 74/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 905us/step - loss: 96100.7500 - val_loss: 96425.2734\n",
      "Epoch 75/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770us/step - loss: 95953.5234 - val_loss: 96421.3438\n",
      "Epoch 76/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - loss: 95856.8672 - val_loss: 96581.2656\n",
      "Epoch 77/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798us/step - loss: 95655.7656 - val_loss: 96343.8594\n",
      "Epoch 78/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 95642.2656 - val_loss: 98287.9219\n",
      "Epoch 79/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step - loss: 95651.4688 - val_loss: 96268.1641\n",
      "Epoch 80/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step - loss: 95610.6953 - val_loss: 96139.6875\n",
      "Epoch 81/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - loss: 95362.0000 - val_loss: 96029.1250\n",
      "Epoch 82/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797us/step - loss: 95544.3672 - val_loss: 95789.3125\n",
      "Epoch 83/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step - loss: 95360.6484 - val_loss: 95929.4062\n",
      "Epoch 84/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 928us/step - loss: 95411.9688 - val_loss: 96189.6328\n",
      "Epoch 85/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901us/step - loss: 95112.8438 - val_loss: 95941.5469\n",
      "Epoch 86/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 95098.1719 - val_loss: 95955.1719\n",
      "Epoch 87/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step - loss: 95064.6562 - val_loss: 95551.9297\n",
      "Epoch 88/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825us/step - loss: 95005.1250 - val_loss: 96039.0781\n",
      "Epoch 89/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 754us/step - loss: 94973.1719 - val_loss: 96640.6328\n",
      "Epoch 90/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797us/step - loss: 94867.9844 - val_loss: 95459.8359\n",
      "Epoch 91/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850us/step - loss: 94869.9766 - val_loss: 95377.0547\n",
      "Epoch 92/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 776us/step - loss: 94702.9688 - val_loss: 95737.3828\n",
      "Epoch 93/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step - loss: 94715.8594 - val_loss: 96038.3125\n",
      "Epoch 94/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - loss: 94631.6875 - val_loss: 95431.3516\n",
      "Epoch 95/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 936us/step - loss: 94692.5078 - val_loss: 95754.7812\n",
      "Epoch 96/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900us/step - loss: 94757.9844 - val_loss: 95152.1406\n",
      "Epoch 97/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 822us/step - loss: 94497.2500 - val_loss: 95082.5156\n",
      "Epoch 98/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step - loss: 94517.4766 - val_loss: 95626.8672\n",
      "Epoch 99/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 990us/step - loss: 94362.6250 - val_loss: 95532.6641\n",
      "Epoch 100/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 777us/step - loss: 94603.9531 - val_loss: 95299.2812\n",
      "Epoch 101/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - loss: 94378.0156 - val_loss: 95052.9922\n",
      "Epoch 102/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 788us/step - loss: 94407.3750 - val_loss: 95003.0781\n",
      "Epoch 103/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - loss: 94468.7031 - val_loss: 95294.2500\n",
      "Epoch 104/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - loss: 94340.3281 - val_loss: 95311.6875\n",
      "Epoch 105/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step - loss: 94268.3750 - val_loss: 95079.1172\n",
      "Epoch 106/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - loss: 94177.1641 - val_loss: 95122.1641\n",
      "Epoch 107/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - loss: 94225.6953 - val_loss: 95166.0938\n",
      "Epoch 108/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 799us/step - loss: 94109.4844 - val_loss: 94906.9141\n",
      "Epoch 109/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834us/step - loss: 94121.6094 - val_loss: 94515.3281\n",
      "Epoch 110/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step - loss: 93822.3828 - val_loss: 94454.9453\n",
      "Epoch 111/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step - loss: 93381.0000 - val_loss: 93604.8672\n",
      "Epoch 112/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step - loss: 92871.3516 - val_loss: 96277.4922\n",
      "Epoch 113/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779us/step - loss: 92518.6094 - val_loss: 93159.0469\n",
      "Epoch 114/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - loss: 91943.6328 - val_loss: 92370.6562\n",
      "Epoch 115/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - loss: 91312.1172 - val_loss: 91764.5156\n",
      "Epoch 116/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 889us/step - loss: 91042.7891 - val_loss: 91110.2656\n",
      "Epoch 117/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901us/step - loss: 90216.4453 - val_loss: 91099.9453\n",
      "Epoch 118/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step - loss: 89552.8672 - val_loss: 89878.2109\n",
      "Epoch 119/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 857us/step - loss: 89082.3984 - val_loss: 89932.0703\n",
      "Epoch 120/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step - loss: 88357.4609 - val_loss: 88838.0859\n",
      "Epoch 121/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - loss: 88050.6719 - val_loss: 88267.8750\n",
      "Epoch 122/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869us/step - loss: 87408.8125 - val_loss: 87951.8047\n",
      "Epoch 123/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step - loss: 87114.2266 - val_loss: 87000.9297\n",
      "Epoch 124/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828us/step - loss: 86198.5625 - val_loss: 86714.4453\n",
      "Epoch 125/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820us/step - loss: 85799.6094 - val_loss: 86201.8672\n",
      "Epoch 126/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 880us/step - loss: 85401.3281 - val_loss: 85517.9531\n",
      "Epoch 127/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898us/step - loss: 84916.1875 - val_loss: 85490.5781\n",
      "Epoch 128/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step - loss: 84582.5859 - val_loss: 86010.7109\n",
      "Epoch 129/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851us/step - loss: 84144.8125 - val_loss: 85182.2109\n",
      "Epoch 130/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838us/step - loss: 83882.6719 - val_loss: 84329.3984\n",
      "Epoch 131/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 786us/step - loss: 83291.1641 - val_loss: 83792.4844\n",
      "Epoch 132/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - loss: 83033.3359 - val_loss: 83663.5547\n",
      "Epoch 133/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 857us/step - loss: 82711.0078 - val_loss: 83405.7266\n",
      "Epoch 134/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 777us/step - loss: 82468.4141 - val_loss: 83234.3047\n",
      "Epoch 135/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868us/step - loss: 82141.8828 - val_loss: 82364.5000\n",
      "Epoch 136/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - loss: 82006.7500 - val_loss: 82687.5078\n",
      "Epoch 137/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step - loss: 81479.2344 - val_loss: 83022.1016\n",
      "Epoch 138/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 81485.8906 - val_loss: 81617.5859\n",
      "Epoch 139/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - loss: 80952.2812 - val_loss: 82106.2188\n",
      "Epoch 140/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850us/step - loss: 80565.4766 - val_loss: 82943.6016\n",
      "Epoch 141/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - loss: 80474.6172 - val_loss: 81025.6562\n",
      "Epoch 142/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - loss: 80328.2344 - val_loss: 80934.4141\n",
      "Epoch 143/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 788us/step - loss: 79902.7891 - val_loss: 80553.3750\n",
      "Epoch 144/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - loss: 80068.7266 - val_loss: 80870.6719\n",
      "Epoch 145/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - loss: 79689.5547 - val_loss: 81071.5781\n",
      "Epoch 146/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - loss: 79531.1641 - val_loss: 80131.5703\n",
      "Epoch 147/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - loss: 79432.7031 - val_loss: 80208.6641\n",
      "Epoch 148/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 922us/step - loss: 79443.9531 - val_loss: 79053.8594\n",
      "Epoch 149/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 945us/step - loss: 78978.8438 - val_loss: 79955.5234\n",
      "Epoch 150/150\n",
      "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 790us/step - loss: 78889.7891 - val_loss: 79279.9766\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x36323a7e0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train, y=y_train.values, epochs=150, validation_data=(X_test, y_test), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "268e1fe1-be6d-4744-b89a-5da0b408fd43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 552us/step\n",
      "[[ 129395.74]\n",
      " [ 444673.6 ]\n",
      " [ 768852.1 ]\n",
      " ...\n",
      " [1276376.5 ]\n",
      " [ 439557.2 ]\n",
      " [ 703143.1 ]]\n",
      "9791      216500.0\n",
      "10281     451000.0\n",
      "19724     780000.0\n",
      "20060     379950.0\n",
      "21204    1061600.0\n",
      "           ...    \n",
      "13212     370000.0\n",
      "8109      440000.0\n",
      "19729     600000.0\n",
      "16123     382500.0\n",
      "20761     739000.0\n",
      "Name: price, Length: 4323, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "print(predictions)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138246c7-70c2-415a-95f9-caf7a44ef60b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (TensorFlow)",
   "language": "python",
   "name": "python312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
